This is an example of the pipeline to be used to measure prediction accuracy and ablation impact for a set of constructions.

It assumes that the experiments are run in an arbitrary directory, so that full paths are specified to the scripts to be run.

SIMPLE

Generate simple sentences:

$ perl ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/generate_relatives.pl 0 300 simple | perl ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/post_process_stimuli_ending_with_verb_to_create_correct_wrong.pl > correct_wrong_simple.txt

Extracting the sentences without the meta-data, and getting the activations:

$ perl -F'\t' -ane 'print $F[0],"\n"' correct_wrong_simple.txt > simple_prefixes.txt

$ python ~/sentence-processing-MEG-LSTM/Code/LSTM/model-analysis/extract-activations.py PATH_TO_MODEL -i simple_prefixes.txt -v PATH_TO_VOCAB -o ./simple_data --eos-separator "<eos>" --format pkl --cuda -g lstm --use-unk --unk-token "<unk>"

(You might want to record perplexity from the output of the script, as a sanity check.)

My PATH_TO_MODEL: private/home/mbaroni/relative_clauses/hidden650_batch128_dropout0.2_lr20.0.pt

My PATH_TO_VOCAB: /private/home/mbaroni/relative_clauses/vocab.txt

Checking accuracy:

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/compute_accuracy.py simple_data.pkl correct_wrong_simple.txt 1 2 2

where the arguments are:

- pkl with the activations

- file with the meta-data itemized by correct and wrong continuations, generated as described above

- index of tab-delimited field with correct/wrong flag in the meta-data file

- index of tab-delimited field with number information in the meta-data file

- index of position of verb for which model prediction accuracy is computed in sentence

All indices count from 0.

Extracting only correct/wrong versions of the sentences where the model correctly favoured the right-agreement version (in the case of simple sentences, this might be equivalent to: select all sentences):

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/get_correct_sentences_and_data.py simple_data.pkl correct_wrong_simple.txt 1 2 2 > temp_good_simple.txt

... with same arguments as above.

Converting to Tal's format for ablation study:

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/convert_sentences_to_tal_format.pl simple temp_good_simple.txt 

where "simple" is the prefix for the output files. The following files will be generated:

simple_plural_sentences.text
simple_plural_sentences.gold
simple_singular_sentences.text
simple_singular_sentences.gold

What follows illustrates how the ablation is run using the Facebook cluster: commands might have to be adapted for running on different clusters.

Create a directory to store the output abl files generated by the ablation script:

$ mkdir simple_ablation

Generating the list of commands (NB: the script has hard-coded paths right now, they must be updated to your own paths, or, better, turned into command-line arguments):

$ bash ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/generate_ablation_commands.sh ./simple ./simple_ablation > temp_simple_ablation_commands.txt

where the first argument specifies the prefix of the Tal-formatted files, the second the target directory.

Running the commands through the FAIR cluster (this requires German's jl.py command scheduling script and to have the stool tool installed--paths mush be updated accordingly).

$ nohup bash ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/run_ablation.sh temp_simple_ablation_commands.txt > temp.out 2> temp.err &

Looking at the output:

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/process_ablation_accuracies.py singular simple_ablation | ...

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/process_ablation_accuracies.py plural simple_ablation | ...


where singular|plural is the prefix of the output abl files to be processed, and simple_ablation is the directory where they reside. The output will likely need further processing (represented here by ...). The tab-delimited format is as follows:

abl_file_name	HITS	TOT_SENTENCES	ACCURACY

for example:

singular20_groupsize_1_seed_111.abl	300	300	1.0

As an example of how to process the output, the following pipeline prints the units that have accuracy below 100%, with the respective accuracy values:

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/process_ablation_accuracies.py singular simple_ablation | sort -nk4 | perl -ne 's/singular//; s/_.*abl//; print' | awk '$4<1{print $1 "\t" $4}' 

ADV

Generating sentences of form "NP ADV V" ("the athlete certainly admires"):

$ perl ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/generate_relatives.pl 0 900 simple_adv | perl ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/post_process_stimuli_ending_with_verb_to_create_correct_wrong.pl > correct_wrong_adv.txt

$ perl -F'\t' -ane 'print $F[0],"\n"' correct_wrong_adv.txt > adv_prefixes.txt

$ python ~/sentence-processing-MEG-LSTM/Code/LSTM/model-analysis/extract-activations.py PATH_TO_MODEL -i adv_prefixes.txt -v PATH_TO_VOCAB -o ./adv_data --eos-separator "<eos>" --format pkl --cuda -g lstm --use-unk --unk-token "<unk>"

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/compute_accuracy.py adv_data.pkl correct_wrong_adv.txt 1 2 3

NB: position of target verb is different, as it will be at index 3 counting from 0, after adverb insertion!

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/get_correct_sentences_and_data.py adv_data.pkl correct_wrong_adv.txt 1 2 3 > temp_good_adv.txt

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/convert_sentences_to_tal_format.pl adv temp_good_adv.txt 

$ mkdir adv_ablation

$ bash ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/generate_ablation_commands.sh ./adv ./adv_ablation > temp_adv_ablation_commands.txt

$ nohup bash ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/run_ablation.sh temp_adv_ablation_commands.txt > temp.out 2> temp.err &

Looking at the output:

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/process_ablation_accuracies.py singular adv_ablation | ...

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/process_ablation_accuracies.py plural adv_ablation | ...

ADV_ADV

Generating sentences of form "NP ADV ADV V" ("the athlete certainly admires"):

$ perl ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/generate_relatives.pl 0 900 adv_adv | perl ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/post_process_stimuli_ending_with_verb_to_create_correct_wrong.pl > correct_wrong_adv_adv.txt

$ perl -F'\t' -ane 'print $F[0],"\n"' correct_wrong_adv_adv.txt > adv_adv_prefixes.txt

$ python ~/sentence-processing-MEG-LSTM/Code/LSTM/model-analysis/extract-activations.py PATH_TO_MODEL -i adv_adv_prefixes.txt -v PATH_TO_VOCAB -o ./adv_adv_data --eos-separator "<eos>" --format pkl --cuda -g lstm --use-unk --unk-token "<unk>"

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/compute_accuracy.py adv_adv_data.pkl correct_wrong_adv_adv.txt 1 2 4

NB: position of target verb is again shifted forward by 1!

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/get_correct_sentences_and_data.py adv_adv_data.pkl correct_wrong_adv_adv.txt 1 2 4 > temp_good_adv_adv.txt

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/convert_sentences_to_tal_format.pl adv_adv temp_good_adv_adv.txt 

$ mkdir adv_adv_ablation

$ bash ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/generate_ablation_commands.sh ./adv_adv ./adv_adv_ablation > temp_adv_adv_ablation_commands.txt

$ nohup bash ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/run_ablation.sh temp_adv_adv_ablation_commands.txt > temp.out 2> temp.err &

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/process_ablation_accuracies.py singular adv_adv_ablation | ...

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/process_ablation_accuracies.py plural adv_adv_ablation | ...

NAMEPP

Generating sentences of form "NP P PNOUN V" ("the athlete near John admires"). Note that in this context all singular-subject sentences are singular/singular cases (attractor agreeing with the subject), and all pural-subject sentences as plural/singular cases (attractor disagreeing with the subject).

$ perl ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/generate_relatives.pl 0 900 simple_namepp | perl ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/post_process_stimuli_ending_with_verb_to_create_correct_wrong.pl > correct_wrong_namepp.txt

$ perl -F'\t' -ane 'print $F[0],"\n"' correct_wrong_namepp.txt > namepp_prefixes.txt

$ python ~/sentence-processing-MEG-LSTM/Code/LSTM/model-analysis/extract-activations.py PATH_TO_MODEL -i namepp_prefixes.txt -v PATH_TO_VOCAB -o ./namepp_data --eos-separator "<eos>" --format pkl --cuda -g lstm --use-unk --unk-token "<unk>"

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/compute_accuracy.py namepp_data.pkl correct_wrong_namepp.txt 1 2 4

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/get_correct_sentences_and_data.py namepp_data.pkl correct_wrong_namepp.txt 1 2 4 > temp_good_namepp.txt

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/convert_sentences_to_tal_format.pl namepp temp_good_namepp.txt 

$ mkdir namepp_ablation

$ bash ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/generate_ablation_commands.sh ./namepp ./namepp_ablation > temp_namepp_ablation_commands.txt

$ nohup bash ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/run_ablation.sh temp_namepp_ablation_commands.txt > temp.out 2> temp.err &

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/process_ablation_accuracies.py singular namepp_ablation | ...

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/process_ablation_accuracies.py plural namepp_ablation | ...

ADV_CONJUNCTION

Generating sentences of form "NP ADV AND ADV V" ("the athlete gently and deliberately greets"):

$ perl ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/generate_relatives.pl 0 600 adv_conjunction | perl ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/post_process_stimuli_ending_with_verb_to_create_correct_wrong.pl > correct_wrong_adv_conjunction.txt

$ perl -F'\t' -ane 'print $F[0],"\n"' correct_wrong_adv_conjunction.txt > adv_conjunction_prefixes.txt

$ python ~/sentence-processing-MEG-LSTM/Code/LSTM/model-analysis/extract-activations.py PATH_TO_MODEL -i adv_conjunction_prefixes.txt -v PATH_TO_VOCAB -o ./adv_conjunction_data --eos-separator "<eos>" --format pkl --cuda -g lstm --use-unk --unk-token "<unk>"

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/compute_accuracy.py adv_conjunction_data.pkl correct_wrong_adv_conjunction.txt 1 2 5

Again, shifting the verb index...

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/get_correct_sentences_and_data.py adv_conjunction_data.pkl correct_wrong_adv_conjunction.txt 1 2 5 > temp_good_adv_conjunction.txt

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/convert_sentences_to_tal_format.pl adv_conjunction temp_good_adv_conjunction.txt 

$ mkdir adv_conjunction_ablation

$ bash ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/generate_ablation_commands.sh ./adv_conjunction ./adv_conjunction_ablation > temp_adv_conjunction_ablation_commands.txt

$ nohup bash ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/run_ablation.sh temp_adv_conjunction_ablation_commands.txt > temp.out 2> temp.err &

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/process_ablation_accuracies.py singular adv_conjunction_ablation | ...

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/process_ablation_accuracies.py plural adv_conjunction_ablation | ...

NOUNPP

Generating sentences of the form "NP P NP V" ("the athlete beside the car avoids"). Note that in this case we have a distractor for both the singular and plural condition (athlete(s)/car(s)), so the analysis will be conducted in terms of the categories: singular_singular, singular_plural, plural_plural and plural_singular.

The extra command-line perl script in the following pipeline creates the composite number tags listed above:

[devfair0283 ~/relative_clauses] mbaroni$ perl ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/generate_relatives.pl 0 600 nounpp| perl -F'\t' -ane 'print join "\t",(@F[0..1],"$F[2]_$F[3]",$F[4])' | perl ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/post_process_stimuli_ending_with_verb_to_create_correct_wrong.pl > correct_wrong_nounpp.txt

$ perl -F'\t' -ane 'print $F[0],"\n"' correct_wrong_nounpp.txt > nounpp_prefixes.txt

$ python ~/sentence-processing-MEG-LSTM/Code/LSTM/model-analysis/extract-activations.py PATH_TO_MODEL -i nounpp_prefixes.txt -v PATH_TO_VOCAB -o ./nounpp_data --eos-separator "<eos>" --format pkl --cuda -g lstm --use-unk --unk-token "<unk>"

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/compute_accuracy.py nounpp_data.pkl correct_wrong_nounpp.txt 1 2 5

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/get_correct_sentences_and_data.py nounpp_data.pkl correct_wrong_nounpp.txt 1 2 5 > temp_good_nounpp.txt

Note that, in the following step, we now generate separate file sets for all possible singular/plural combinations:

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/convert_sentences_to_tal_format.pl nounpp temp_good_nounpp.txt 

$ mkdir nounpp_ablation

$ bash ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/generate_ablation_commands.sh ./nounpp ./nounpp_ablation > temp_nounpp_ablation_commands.txt

$ nohup bash ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/run_ablation.sh temp_nounpp_ablation_commands.txt > temp.out 2> temp.err &

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/process_ablation_accuracies.py singular_singular nounpp_ablation | ...

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/process_ablation_accuracies.py singular_plural nounpp_ablation | ...

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/process_ablation_accuracies.py plural_plural nounpp_ablation | ...

$ python ~/sentence-processing-MEG-LSTM/Code/Stimuli/Relative_clause_Marco/process_ablation_accuracies.py plural_singular nounpp_ablation | ...
