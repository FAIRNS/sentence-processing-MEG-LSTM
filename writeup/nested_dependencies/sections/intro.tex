\section{Introduction}
The prevailing view in linguists suggests that the rich expressiveness and open-ended ability of human language require the postulation of a computational competence to process nested tree structures, possibly unique to humans, which is based on \textit{recursion}. \cite{Chomsky:1957, Hauser:etal:2002, Dehaene:etal:2015}. The notion of recursion was developed in the study of human linguistic \textit{competence}, which is described by a set of rules from which acceptable strings of a language can be generated. If a certain recursive construction can be generated from the grammar by an application of a rule, then a repeated application of the same rule could generate acceptable strings of an arbitrarily recursive complexity. In contrast, it is empirically established that human linguistic \textit{performance} is tightly limited in terms of processing complex nested constructions \citep{}. This is due to various resource limitation, such as memory capacity or attention span. This distinction between the bounded performance of humans and their unbounded competence renders the notion of recursion an appealing solution to this contrast. Recursion suggests a computational mechanism that can process an unbounded number of expressions using only finite means.

In recent years, neural-networks models showed tremendous advances in natural language processing, reaching remarkable performance on various linguistic tasks. Typically, neural-networks models are not provided with any explicit information regarding the grammar or any type of linguistic knowledge. For example, Neural Language Models (NLMs) are commonly initialized as `tabula rasa' and are solely trained to predict the next word in the sentence given its context \citep{Elman:1990}. Yet, these models achieve an impressive performance that resembles that of humans \citep{}. This has naturally attracted recent interest into \textit{how} exactly these models perform the task, and in particular, it raises the question - do these models learn recursion?

However, this question should be refined and further specified. The notion of recursion challenges NLMs, since recursion construed as a computational mechanism would be essentially symbolic, as was classically argued \citep{Fodor:Pylyshyn:1988}. Moreover, in NLMs there could not be a distinction between an `ideal' grammar and its realized processing. NLMs learn the linguistic rules from the data during training. These rules are then encoded in the network in a way that is inevitably directly related to the way the network applies them during sentence processing \citep{van_gelder}. In the study of NLMs, the competence-performance distinction therefore does not hold, nor the idea of recursion as an elegant solution to the contrast between the unbounded competence and bounded human performance. The above question should therefore be revised, e.g. - do NLMs show recursive performance?

In the present study, we start by investigating into recursive performance in NLMs, using number-agreement as a probe into their syntactic processing. Number agreement is considered as one of the best indexes of online syntactic processing in humans \citep{Bock:Miller:1991, franck2002subject}, and was recently introduced also into the study of NLMs \citep{Linzen:etal:2016}. Treating NLMs as psycholinguistic subjects, most current research in the field focuses on understanding the behaviour of NLMs with respect to various grammatical phenomena, with some work also showing correlations between internal states of the model and said phenomena. Number agreement is an area where some steps have been taken towards mechanistic understanding. Specifically, in a recent study, we showed that NLMs trained on a large corpus of English developed a number-propagation mechanism for long-range dependencies \citep{lakretz2019emergence}. The core circuit of this mechanism was found to compose of an exceptionally small number of units in the network, namely, three, out of 1300 units in the network. Despite its sparsity, this mechanism was shown to carry grammatical number information across various and challenging long-range dependencies, also in the presence of intervening nouns carrying opposite number. However, given the sparsity of the mechanism, it remains unclear how the network would process recursive structures having more than a single long-range dependency, such as in the case of nested dependencies.

The goal of this present study is three-fold. First, we test whether our results about a sparse agreement mechanism in NLMs can be extended to another language (Italian) and to a another grammatical feature (gender). Second, we test whether NLMs can process recursive nested dependencies despite the sparsity of the agreement mechanism. Finally, based on the results and our understanding of how agreement is performed by NLMs, we make predictions about recursive processing in human performance. 

Our results replicate in an Italian NLM our previous findings in English. We further find that the sparsity of the agreement mechanism strongly constrains the NLM in the processing of nested structures, causing a significant reduction in performance on the embedded dependency. Finally, results from a behavioral experiment with humans confirmed our predictions regarding the processing of nested long-range dependencies, showing similar error patterns between NLMs and humans. 

We conclude that the emergence of a sparse long-range agreement mechanism in NLMs is a robust phenomenon, consistently observed across models, languages and grammatical features. We further conclude that NLMs do not exhibit recursive performance in the processing of nested long-range dependencies. Finally, the similarity between NLM and human error patterns suggests that the low recursive performance of humans could be explained by similar mechanisms to those identified in NLMs. 

\YL{I kept this paragraph from the skeleton you sketched, but we could also end the discussion/conclusion section with it instead of here.} However, in other ways, human and NLM patterns differ, confirming that studying NLMs is productive, but the right perspective is not to treat them as full-fledged cognitive models, but rather as powerful computational systems that, when faced with challenges similar to those encountered by humans, might adopt partially analogous solutions.
