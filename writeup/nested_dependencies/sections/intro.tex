\section{Introduction}

According to a popular view in linguistics, the rich expressiveness and open-ended nature of language rest on \emph{recursion}, the possibly uniquely human ability to process nested structures \citep{Chomsky:1957, Hauser:etal:2002, Dehaene:etal:2015}. 
We currently know very little about how such ability is implemented in the brain, and consequently about its scope and limits.

In recent years, artificial neural-network models, rebranded as ``deep learning'' \citep{LeCun:etal:2015}, made tremendous advances in natural language processing \citep{Goldberg:2017}. Typically, neural networks are not provided with any explicit information regarding grammar or other types of linguistic knowledge. Neural Language Models (NLMs) are commonly initialized as ``tabula rasa'' and are solely trained to predict the next word in a sentence given its context \citep{Mikolov:2012}. Yet, these models achieve impressive performance, not far below that of humans, in tasks such as question answering or text summarization \citep{Radford:etal:2019}. 

Unlike their connectionist progenitors \citep{Rumelhart:etal:1986,Rumelhart:etal:1986b}, modern NLMs are not intended as cognitive models of human behaviour. 
They are instead developed to be deployed in applications such as translation systems or online content organizers. 
Nevertheless, \emph{recurrent} NLMs  \citep{Elman:1990,Hochreiter:Schmidhuber:1997}, at least, do share some relevant attributes with the human processing system, such as the property that they receive input incrementally  and process it in a parallel and distributed way. Furthermore, NLMs' success in the practical natural language arena strongly suggests that they must infer non-trivial linguistic knowledge from the raw data they are exposed to. % This has attracted the interest of linguists and cognitive scientists, curious to know  \textit{how} exactly NLMs handle grammatical structure \citep[see][for a survey]{Linzen:Baroni:2020}.
Combined, these two facts make NLMs akin to an interesting `animal species', whose way to address a linguistic task might provide insight into how the human processing system might be tackling similar challenges \citep[see also][]{McCloskey:1991}.

By relying on these epistemological insights, we perform here an in-depth analysis of nested processing in NLMs. 
We uncover the neural circuitry they develop to handle it, and we use it to make predictions about human language processing. 
%Importantly, we are not making claims about NLMs being models of the human brain. 
%Rather, following \citet{McCloskey:1991}, we treat NLMs as a separate `animal species', whose way to address a linguistic task can provide insights into how the human brain might be tackling similar challenges.
%

Specifically, we explore multiple-structure nesting in the context of grammatical agreement. Long-distance agreement has traditionally been studied as one of the  best indices of online syntactic processing in humans, as it is ruled
by hierarchical structures rather than by the linear order of words in
a sentence \citep{Bock:Miller:1991, franck2002subject}. Consider for example the sentence: ``The \textbf{boys} under the \underline{tree} \textbf{know} the farmers'', where the number of the verb (`know') depends on its linearly distant subject (`boys'), and not on the immediately preceding noun `tree'.

Number agreement has also become a standard way to probe grammatical
generalization in NLMs \citep{Linzen:etal:2016,Bernardy:Lappin:2017,Giulianelli:etal:2018,Gulordava:etal:2018}. Very
recently, some steps were taken towards a mechanistic understanding of
how NLMs perform agreement. Specifically, \citet{lakretz2019emergence} showed that NLMs trained
on a large corpus of English developed a number-propagation mechanism for long-range dependencies. The core circuit of this mechanism is sparse, in the sense that it is comprised of an exceptionally small number of units (three out of 1300). This mechanism carries grammatical number information across various and challenging long-range dependencies, also in the presence of intervening nouns carrying opposite number.

The recursive power of language allows the construction of sentences with multiple nested agreement dependencies, as in: ``The \textbf{boys} that the \textit{father} under the \underline{tree} \textit{watches} \textbf{know} the farmers''. The mechanism we outlined above should be robust to the intervention of nested hierarchical structures, thus allowing correct percolation of number across the outermost long-distance agreement dependency (`boys/know'). However, the sparsity of the solution found by NLMs implies that only a number feature at a time can be tracked, thus predicting failure to handle \emph{embedded} dependencies within multiple nestings (`father/watches' in the example above). Intuitively, once the mechanism is ``filled'' by the outermost
dependency, it should not be able to track further number features.

We  start by confirming that the emergence of a sparse
agreement mechanism is a stable and robust phenomenon in NLMs by
replicating it with a new language (Italian) and grammatical feature
(gender). Next, we study how the sparsity of the agreement mechanism
affects recursive agreement processing, confirming our predictions
that the mechanism supports outermost agreement across nested
structures, but not multiple embedded agreements.

In the next part of the study, we treat our mechanistic understanding of
agreement in NLMs as an ``hypothesis generator''
\citep{Cichy:Kaiser:2019} about nested agreement processing in
humans. Suppose humans are also using a relatively small fraction of specialized units
to store and release agreement features across long-distance syntactic
structures. Then, we might observe a similar asymmetry in handling
outer- and innermost dependencies in recursive structures. We run a
behavioural experiment with Italian subjects to test this
hypothesis. The results are intriguing. One the one hand, humans do
not display the same dramatic failure to process embedded dependencies we observed in NLMs. However, they are indeed more prone to errors in embedded dependencies than in the longer-range outer ones, in accordance with our predictions. Moreover, a comparison between NLM and human results reveal overall remarkable similarity. 

Our results thus indicate that NLMs do not establish a genuine mechanism for recursive processing of nested long-range agreements. However, they also also show how some degree of hierarchical processing can be performed by a device, such as the NLM, that did not develop full recursive capabilities. Furthermore, the similarity between the error patterns of humans and the model illustrate how % that modern NLMs as compelling models for the study of language processing in humans, and our study shows how 
a detailed understanding of emergent mechanisms in NLMs leads to hypotheses about hierarchical structure processing that are relevant to human language parsing.


% We conclude by outlining future experiments that should allow to distinguish between two interpretations of the current data. According to one interpretation, humans' nested feature processing is radically different from the one emerging in NLMs, and genuinely capable of unbound recursive processing, limited only by finite resources. According to the other, humans' feature processing mechanism is akin to the one of NLMs, but only differs quantitatively. 

% Overall, our study illustrates how some degree of hierarchical processing can be performed by a device, such as an NLM, that did not develop full recursive capabilities. It also shows how a detailed understanding of emergent mechanisms in modern NLMs can lead to new and precise tests of human hierarchical structure processing.


%they also possess sophisticated backup mechanisms beyond the abilities developed by NLMs.


% \textbf{Earlier version of intro commented out below this line.}

% The prevailing view in linguistics suggests that the rich
% expressiveness and open-ended nature of human language require a
% computational ability to process nested tree structures, possibly
% unique to humans, which is based on
% \textit{recursion}. \citep{Chomsky:1957, Hauser:etal:2002,
%   Dehaene:etal:2015}. This view was developed in the context of the
% study of human linguistic \textit{competence}, which is described by a
% set of rules from which acceptable strings of a language can be
% generated. If a certain recursive construction can be generated from
% the grammar by the application of a rule, then a repeated application
% of the same rule could generate acceptable strings of an arbitrarily
% recursive complexity. In contrast, it is empirically established that
% human linguistic \textit{performance} is tightly limited in terms of
% processing complex nested constructions, due to various resource
% limitation, such as memory capacity or attention span \citep{}.

% In recent years, artificial neural-network models, rebranded as ``deep learning'' \citep{LeCun:etal:2015}, made tremendous advances in natural language processing \citep{Goldberg:2017}. Typically, neural networks are not provided with any explicit information regarding grammar or any type of linguistic knowledge. For example, Neural Language Models (NLMs) are commonly initialized as `tabula rasa' and are solely trained to predict the next word in the sentence given its context \citep{Elman:1990}. Yet, these models achieve an impressive performance not far below that of humans in tasks such as question answering or text summarization \citep{Radford:etal:2019}. This has naturally attracted recent interest into \textit{how} exactly these models perform the task, and the degree to which they infer genuine linguistic knowledge from raw data  \citep{}, with the ultimate hope that this will also provide insights into human language processing. 

% Grammatical agreement has traditionally been studied as one of the
% best indices of online syntactic processing in humans, as it is ruled
% by hierarchical structures rather than linear by the order of words in
% a sentence \citep{Bock:Miller:1991, franck2002subject}. Number
% agreement has also become a standard way to probe grammatical
% generalization in NLMs
% \citep{Linzen:etal:2016,Bernardy:Lappin:2017,Giulianelli:etal:2018,Gulordava:etal:2018}. Very
% recently, some steps were taken towards a mechanistic understanding of
% how NLMs perform agreement. Specifically, \citet{lakretz2019emergence} showed that NLMs trained
% on a large corpus of English developed a number-propagation mechanism for long-range dependencies. The core circuit of this mechanism is comprised of an exceptionally small number of units (three out of 1300). Despite its sparsity, this mechanism carries grammatical number information across various and challenging long-range dependencies, also in the presence of intervening nouns carrying opposite number. However, given the sparsity of the mechanism, it remains unclear how the network would
% process recursive structures having more than a single long-range
% dependency, such as in the case of multiple nested dependencies:
% Intuitively, once the mechanism is recruited by the outermost
% dependency, it is not able anymore to track the ones nested inside it.

% \dnote{I think this transition is difficult and doesn't do completely justice to what we do. Could we maybe add a few more sentences about recursion in networks? Or link it back to competence/performance again? It is important that the reader gets here the importance of what we try to do, I think it should sound less incremental than it sounds here.}
% In the present study, we start by investigating the recursive
% performance of NLMs, using number-agreement as a
% probe. We first confirm that the emergence of a sparse agreement mechanism is
% a stable and robust phenomenon in NLMs by replicating it with a new
% language (Italian) and grammatical feature (gender). Next, we study
% how the sparsity of the agreement mechanism affects recursive
% agreement processing, confirming our predictions that the mechanism
% strongly binds the depth of recursion. Finally, we test whether the
%  system we saw emerge in NLMs could serve as a
% model of recursion processing limitations in humans. The results of a
% behavioural study partly confirm our predictions, showing largely similar error patterns between NLMs and humans. 
% \YL{Add a sentence about differences}

% \textbf{Add boastful wrap-up sentence.}