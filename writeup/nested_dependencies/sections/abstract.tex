\abstract{Recursive processing in sentence comprehension is considered a hallmark of human linguistic abilities. However, its underlying neural mechanism in the human brain remains largely unknown. Neural Language Models (NLMs) have recently shown remarkable success on various linguistic tasks. As the only non-human computational systems capable of accomplishing such tasks, NLMs offer new opportunities to study low-level mechanisms underlying natural language processing, which might give insights about human linguistic parsing. Here, we study syntactic processing in a recurrent NLM with Long Short-Term Memory units. We use subject-verb number agreement as an index of syntactic processing in the NLM, and investigate the neural mechanisms underlying its processing of nested agreement--a prototypical case of recursion. We find a small set of specialized units in the model that can successfully handle the outermost agreements of nested constructions. 
An analysis of this mechanism predicts that, as it does not support full recursion, it will run into trouble when processing embedded dependencies, especially if they are in turn long-range. We confirm this in simulations, and further derive predictions about human performance based on the properties of the NLM agreement mechanism, which we test in a behavioral experiment. Unlike the NLM, humans do not exhibit a dramatic failure on embedded long-range dependencies. However, human and NLM error patterns are remarkably similar, showing that NLMs echo various effects observed in human data. Overall, our study shows that exploring the ways in which NLMs process sentences leads to precise and testable hypotheses about human linguistic performance, establishing modern NLMs as compelling 'animal' models for research on natural language processing.}