\section{General Discussion}
% Re-iteration on the motivations and goals
We investigated how recursive processing of number agreements is performed by Neural Language Models (NLMs), considering them as `hypothesis generators' for understanding human natural-language processing. To this end, we contrasted processing of NLMs of successive and nested constructions, and tested resulting predictions about human performance. 

% Summary of the results on a single dependency in NLMs
\subsection{A Sparse Agreement Mechanism Consistently Emerges in NLMs Across Languages and Grammatical Features}
Using number-agreement tasks with a single subject-verb dependency, we first replicated in Italian previous findings reported for an English NLM, and extended these findings to another grammatical feature, namely, gender. We found that for both number and gender agreement a sparse mechanism emerged in an Italian NLM during training. These findings suggest that the emergence of a sparse agreement mechanism in NLM is a robust phenomenon across languages and grammatical features. 

These results are consistent with previous findings, showing that a sparse agreement mechanism emerged in an NLM trained on an artificial language having deep nested structures (i.e., with more than two levels of nesting), suggesting that the sparsity property is not due to the rare occurrence of deep nested structures in natural language \citep{lakretz2020recursion}. 

The sparsity and specificity of the agreement mechanism suggests that NLMs develop a separate `module' dedicated for grammatical processing. While the related grammatical information is encoded by a small number of syntax and long-range feature units, non-grammatical information, such as semantic information, is high-dimensional, encompassing complex similarity relations among items, and thus benefits from rather distributed encoding across many units. Indeed, NLMs commonly develop dense representations for the processing of semantic information, by mapping discrete symbols from the lexicon to continuous vectors in a relatively low-dimensional space, determined by the input embedding layer (Materials and Methods). The sparsity and specificity of the agreement mechanism in NLMs therefore suggests the separate processing of grammatical and semantic information in the newtork. 

In the human brain, it remains an open question whether semantic and syntactic information is encoded and processed jointly or separately in the `language network' \citep{pallier2011cortical}. Traditionally, it is thought that syntactic processing takes place in localized brain regions, such as Broca's area \citep[e.g.,][]{dapretto1999form}. However, other studies cast doubt on this view, providing evidence for that semantic and syntactic processing in the language network cannot be dissociated from one another \citep{mollica2018high, siegelman2019attempt, fedorenko2020lack}. There are clearly substantial differences between the human brain and NLMs, however, it is interesting to note that our findings suggest that separating syntactic from semantic processing is computationally advantageous for addressing the language-modelling task \citep[see, e.g.,][for related studies.]{ullman2004contributions, o2006biologically, russin2019reilly} 

% Summary of the results on two dependencies in NLMs
\subsection{Processing of Nested Dependencies in Humans and NLMs}
We next explored agreement processing of recursive structures that comprise a subject-verb dependency nested within another one. We first confirmed the prediction based on the sparsity of the agreement mechanism in NLMs, showing that the network exhibits exceptional processing difficulty in processing an embedded long-range dependencies in a nested construction. Since NLMs seem to lack a recursive procedure to handle multiple dependencies, once the number units are taken up for the encoding of the outermost dependency, the network fails to process an embedded long-range dependency. In contrast, we found that NLMs achieve relatively good performance on processing \textit{short-range} embedded dependencies, as they can rely on grammatical-number encoded in the short-range number units. The cooperation between the long- and short-range mechanisms in NLMs therefore allows the network to support the processing of a large proportion of agreement constructions in natural language, failing substantially on only relatively uncommon constructions, having two nested dependencies that are both long-range. 

Human results were found to have both similarities with the agreement-error patterns of NLMs and several important points of discrepancy:

\subsubsection{Main Similarities}
\begin{itemize}
    \item \textbf{Low error-rates on successive dependencies}: humans and the NLM made a relatively small number of agreement errors on the embedded verb of successive dependencies. For NLMs, this is in accordance with the sequential processing observed in its dynamics Figure \ref{fig:2by2_dynamics}. The agreement mechanism resets after the first dependency and is thus available to process the second one. For humans, these findings are in accordance with the relatively good performance of humans on right-branching constructions.
    \item \textbf{Subject-congruence effect in nested constructions}: in the case of a plural subject attractor, for all verbs, both humans and NLMs made significantly more errors in incongruent cases, in which the main and embedded subjects had opposite grammatical numbers.
    \item \textbf{Higher error-rate on embedded compared to main verbs of nested dependencies}: a positive interaction between verb position and subject congruence was found for both short- and long-range embedded dependencies, suggesting that embedded verbs are more error prone, confirming \textit{Prediction 1}.

    
\end{itemize}

\subsubsection{Main Differences}
    \begin{itemize}
        \item \textbf{NLM performance is worse than chance level on the embedded verb of Long-Nested}: the major difference between the NLM and human performance (Figures \ref{fig:error_rates_plural_subject}\&\ref{fig:error_rates_all_conditions}) is the performance of the NLM on the embedded verb in Long-Nested. The NLM was found to be worse than chance level, meaning that in most trials the network predicts the grammatical number of the embedded verb based on the number of the main subject, which is encoded and carried by the agreement mechanism. In contrast, human performance is better than chance level (although only marginally so, $p-value = 0.028$).
        \item \textbf{Prediction 2 was not confirmed in humans}: the NLM made signifcanlly more errors on the embedded dependency when the dependency was long- compared to short-range. This was not confirmed in humans performance, the interaction between subject-congruence and length of the embedded dependency was not significant, although humans made more errors in the long-range case.
        \item \textbf{Absence of markedness effect in the NLM}: while humans made more agreement errors on the embedded dependency when the attractor was plural compared to singular, markedness effect was not observed for the NLM, or was in the opposite direction in some cases. 
    \end{itemize}
    

Baring in mind that the NLM is trained on non-annotated data, and thus no grammatical knowledge is provided to the model, the points of similarity between the error patterns of humans and the NLM are intriguing. In successive constructions, the sequential processing by the agreement mechanism explains the low error rate of the NLM, similarly to that of humans. In nested constructions, the cooperation between short- and long-range mechanisms produces agreement-error patterns that are comparable to those observed in humans, with the exception of performance on the embedded verb in Long-Nested. 

However, the points of discrepancy raise doubts whether the agreement mechanisms in NLMs could be of any cognitive relevance. The NLM might have developed such mechanisms as a sophisticated solution for the language-modelling task, allowing the network to achieve high performance on most encountered structures in the data, without developing linguistic abilities akin to that of humans. On such interpretation, the relatively uncommon construction Long-Nested unveils the limitation of the network, pointing out a major difference between humans and the network. Moreover, the agreement mechanisms of the NLM do not support recursive processing. In Short-Nested, the network processes nested dependencies by the collaboration of two \textit{distinct} mechanisms (i.e., short- and long-range). In contrast, a recursive mechanism for handling possibly infinite nested constructions, limited by only finite resources, would presumably exhibit self-similarity when processing a subsequent level of the recursive structure.

On the other hand, human performance is known to be similarly constrained by nested constructions. Already one level of nesting, as in object-extracted relative clauses, is known to be relatively difficult to parse \citep[e.g.,][]{traxler2002processing}, and although humans can process two long-range dependencies that are active simultaneously (for example, ``The fact that the employee who the manager hired stole office supplies worried the executive'' \citep{Gibson:1998}), these constructions are quite demanding and are therefore less common in natural language. All the more so, two levels of nesting, such as doubly center-embedded sentences, are known to be already impossible to process, and are thus virtually non-existent in natural language \citep{}. Consequently, agreement mechanisms that handle only relatively shallow grammatical dependencies might be nonetheless a computational solution relevant to cortical dynamics in some brain regions. If so, the main discrepancy with respect to Long-Nested might turn out mere quantitative - while NLMs can handle only a single long-range dependency and fail on two, humans can handle two simultaneously active long-range dependencies but would fail on three. Further experiments are required to evaluate such interpretation of the results.


\subsection{Psycholinguistic Theories for Agreement Processing}
Several theories have been suggested in the psycholinguistic literature for grammatical agreement processing in humans, based on agreement-error data. We now discuss our results in light of some of these theories, which may provide a complementary high-level explanations to that suggested by the neural model. 

\subsubsection{Feature Percolation Theories}
% Some background (possibly unnecessary if discussion gets too long)
Early psycholinguistic theories suggested that the proximity between an intervening noun and a verb determines the probability of making an agreement error \citep{quirk1972grammar}. This `linear-distance hypothesis' was later rejected by empirical findings showing that error rates across a prepositional phrase (PP) are higher compared to those across a relative clause, although in the former case, the subject was closer to the verb and the syntactic complexity of the preamble was smaller \citep{bock1992regulating}. Following these findings, B\&C suggested the `clause-packaging hypothesis', stating that an attractor within the same clause would generate more interference than one in another structural unit. 

More recent studies suggested the `syntactic-distance hypothesis' \citep{vigliocco1995constructing, vigliocco1999sex, franck2002subject}, according to which agreement errors depend on the syntactic distance between the head noun and attractor along the syntactic tree. According to this view, the grammatical feature of the attractor is assumed to `percolate’ up the syntactic-tree during incremental processing. Such feature percolation can influence the grammatical agreement between the head noun and verb through interference. Feature percolation is assumed to occur incrementally during sentence processing, therefore, the longer the distance from the attractor to the subject-verb path, the lower the likelihood of interference is. The syntactic-distance hypothesis was shown to account for the reduced error rates across relative-clauses compared a PP, and for additional evidence to which the clause-packaging hypothesis was shown to provide inadequate predictions \citep{franck2002subject}.

Feature percolation naturally accounts for the plural markedness effect assuming singular as the default unmarked feature value,
%\citep{trubetskoy1939grundzuge} 
since when the attractor is singular there should be no upward percolation, and therefore a lower error-rate compared to the plural, marked, case \citep{pearlmutter1999agreement}. However, percolation theories have difficulties to account for agreement errors on embedded dependencies, such as in Short- and Long-Nested. In these constructions the attractor with respect to the embedded dependency is the main subject, and thus resides higher on the syntactic tree. As \citet{wagers2009agreement} note, percolation in such constructions is thus required to happen downwards, whereas percolation theories traditionally assume upward movement through the tree, which could not explain the observed subject-congruence effects. Moreover, the syntactic distance between the main and embedded subjects is much greater than that between the subject and attractor in simple constructions as across a PP. This predicts lower error-rates than those reported for PP constructions. However, our results show higher error-rate on the embedded verb compared to previously reported errors on PP constructions \citep{vigliocco1995constructing}.

\subsubsection{Memory-based theories}
In sentence comprehension, previous findings reported processing facilitation in ungrammatical sentences due to attraction effects \citep[e.g., ][]{pearlmutter1999agreement, wagers2009agreement, lago2015agreement}. Using self-paced reading paradigms, humans were found to process the words following the verb faster in the presence of a plural attractor. Importantly, this effect was reported only for ungrammatical sentences. To account for this grammatical asymmetry, previous studies suggested that a cue-based memory retrieval processes \citep{lewis2005activation} is triggered as a repair mechanism following a violation, which, in contrast, would not be triggered in grammatical sentences having no violation. This cue-based memory retrieval process is error prone, and can thus license a wrong verb form in an ungrammatical sentence, explaining the facilitation observed after the verb in ungrammatical sentences only. 

% We briefly describe the dynamics of the cue-based memory retrieval. 
Based on the Adaptive Control of Thought-Rational architecture (ACT-R; \citet{anderson2013architecture}) to sentence processing, \citet{lewis2005activation} suggested that during incremental processing, the transient syntactic structure of the sentence is represented across memory `chunks’ in declarative memory. During sentence processing, each new word triggers a memory retrieval, at the end of which, the word is integrated into one of the memory chunks. In the case of verbs, at the end of the retrieval process, the verb will be associated with the appropriate subject stored in memory, ideally, having the same grammatical number. During retrieval, a `competition' among memory chunks takes place, and the chunk with the greatest number of features that match the verb is most likely to be retrieved. However, erroneous retrievals can occur, due to similarity between memory chunks and noise, in which case a violation on a verb, carrying the wrong number, might be licensed. 

Cue-based retrieval processes were proposed as a repair mechanism, which are triggered in the case of a violation \citep{wagers2009agreement, lago2015agreement}. For example, for the nested constructions Short- and Long-nested, during the processing of the relative clause, a prediction about the number of the embedded verb is generated. If the embedded verb violates this prediction, as in the case of ungrammatical sentences, a cue-based retrieval is triggered in order to check whether the correct feature was missed. An erroneous retrieval can then license a verb with the wrong number, leading to facilitated reading afterwards. In grammatical sentences, no prediction violation occurs and therefore the repair mechanism will not be triggered, explaining the grammatical asymmetry described above. 

In our study, a violation-detection paradigm was used, and therefore a direct comparison with the results from the described self-paced reading experiments and the ACT-R based model is not possible. However, we note that processing times on the embedded and main verbs as predicted by the ACT-R based model are consistent with our findings. Simulations of sentence processing in the ACT-R based model predict greater processing times on embedded compared to main verbs \citep{lewis2005activation}. This increase in processing time is due to higher similarity among memory items at the time of the presentation of the embedded verb, and therefore more interference and processing slowdowns arise. A cue-based retrieval as a repair mechanism account would thus predict more errors on embedded compared to main verbs in nested constructions. 

However, since processing times cannot be directly mapped onto agreement errors, simulation work would be necessary for generating agreement-error patterns from the ACT-R model for a quantitative comparison, which is beyond the scope of the current study. We further note that a key difference in the error generation process between the two models is that while in the ACT-R based model errors arise during the retrieval process, which occurs after the presentation of the verb, in the NLM, agreement errors are estimated one time step before the verb, and are due to a wrong prediction of the next verb. Agreement errors on ungrammatical sentences in the two models are therefore due to different dynamics - erroneous retrievals vs. erroneous predictions. A possible integration of these different dynamics is an interesting topic for future work.


\section{Conclusions}
We found that the Neural Language model fail to find recursive processing of nested constructions. The networks develop agreement mechanisms for handling only shallow nested constructions, which limits its capacity to process nested constructions. However, the NLM was shown to account for various effects in the patterns of human agreement-error data, showing remarkable similarity across various sentence constructions. While being trained on non-annotated natural-language data, NLMs have a key advantage compared to existing psycholinguistic theories as they do not require to pre-suppose a grammar or a parsing algorithm. NLMs learn to represent and process underlying structures in natural language by mere training on the language-modelling task. 

Overall, this study shows that understanding emerging mechanisms in NLMs proposes novel and testable theories about linguistic processing in humans, together with testable prediction about cortical dynamics by suggesting a mechanistic understanding of natural-language processing. We conclude that modern NLMs provide compelling models for the study of language processing in human, which can inform research in psycho- and neuro-linguistics. 