
\section{Related work}

Starting with the seminal work of \newcite{Linzen:etal:2016},
long-distance number agreement (``the \textbf{boy} near the cars
\textbf{greets}\ldots'') has emerged as a standard way to probe the
syntactic capabilities of RNNs. Following
mixed initial results by Linzen and colleagues and
\newcite{Bernardy:Lappin:2017}, \newcite{Gulordava:etal:2018} and
\newcite{Kuncoro:etal:2018a} have robustly established that LSTMs
trained with the language modeling objective on raw data achieve
near-human performance on the agreement task. While Gulordava and
colleagues provided some evidence that the LSTMs are relying on
genuine syntactic generalizations, \newcite{Kuncoro:etal:2018b} and
\newcite{Linzen:Leonard:2018} suggested that the LSTM achievements
can, at least in part, be accounted by superficial heuristics (e.g., ``percolate the number of the first noun in a sentence''). Other
recent work has extended syntax probing to other phenomena such as
negative polarity items and island constraints
\cite{Chowdhury:Zamparelli:2018,jumelet2018language,marvin2018targeted,wilcox2018rnn}.

While \newcite{Linzen:etal:2016} presented intriguing qualitative data
showing cells that track number in a network specifically trained on
the agreement task, most work of this sort focuses on testing the
network output behaviour, rather than on understanding how the latter
follows from the inner representations of the network. Another research line
studied linguistic processing in neural networks through `diagnostic classifiers', that is, classifiers trained to
predict a certain property from network activations
\cite[e.g.,][]{gelderloos2016phonemes,Adi:etal:2017,alain2017understanding,Hupkes:etal:2017}. This approach may give insight into which information is encoded by the
network in different layers or at different time points, but it only
provides indirect evidence about the specific mechanics of linguistic
processing in the network.

Other studies are closer to our approach in that they attempt to
attribute function to specific network cells, often by means of
visualization
\cite{Karpathy:etal:2016,li2016visualizing,tang2017memory}. \newcite{Radford:etal:2017},
for example, detected a ``sentiment'' grandmother cell in a
language-model-trained network.  \newcite{Kementchedjhieva:Lopez:2018}
recently found a character-level RNN to track morpheme boundaries in a
single cell. We are however not aware of others studies systematically
characterizing the processing of a linguistic phenomenon at the level of
RNN cell dynamics, as is the attempt in the study hereby presented.


% E.g., \newcite{gelderloos2016phonemes} find evidence that a multilayer
% RNN trained in a visually grounded learning paradigm learns to
% represent linguistic information in a hierarchy, encoding form in the
% lower and meaning in the higher layers.  \dieuwke{This is of course
%   not very extensive, but maybe this is not really the place to put a
%   too elaborate analysis?}

% \paragraph{Behavioral studies}
% An entirely different line of research concerning understanding how RNNs process different types of phenomena by looking at their behavior when presented with carefully selected inputs.
% A large part of these studies has focusses on using the perplexity assigned to different sentences by a neural language model to investigate a range of (psycho)linguistic phenomena, such as subject-verb agreement \cite{Linzen:etal:2016,Bernardy:Lappin:2017,Gulordava:etal:2018,Kuncoro:etal:2018a,Kuncoro:etal:2018b,Linzen:Leonard:2018}, negative polarity items \cite{marvin2018targeted,jumelet2018language} and filler-gap dependencies \cite{wilcox2018rnn}.
% Their results -- LSTM language models are capable of correctly processing a number of such interesting linguistic phenomena -- are the premise of our study, in which we investigate \textit{how} they do so.

% \paragraph{Neuroscientific studies}
% \dieuwke{Should we include a section like this to refer to Nelson but potentially also other studies that present a more neurosciency take on this?}
% - Relate to Nelson et. al 2017 PNAS, an intracranial study that identifies electrodes whose high-gamma activity correlates with syntactic tree-depth (numnber of open nodes)
