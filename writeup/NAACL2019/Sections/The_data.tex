\section{Data}
\subsection{Number-agreement tasks}

\begin{table}[tb]
  \centering
  \begin{footnotesize}
  \begin{tabular}{l@{\hskip1pt}l}
    \B Simple & the boy greets the guy\\
    \B Adv & the boy probably greets the guy\\
    \B 2Adv & the boy most probably greets the guy\\
    \B CoAdv &  the boy openly and deliberately greets the guy\\
    \B NamePP & the boy near Pat greets the guy\\
    \B NounPP & the boy near the car greets the guy\\
    %\B SubjRel & the boy that avoids the girl greets the guy\\
    %\B ObjRel  & the boy that the girl avoids greets the guy \\
    %\B ObjRel0 &  the boy the girl avoids greets the guy\\
  \end{tabular}
  \end{footnotesize}
  \caption{NA tasks illustrated by representative
    singular sentences.}
  \label{tab:data-sets}
\end{table}

We generated number-agreement tasks (NA-tasks) with fixed syntactic
structures and varied lexical material that probe subject-verb number
agreement in increasingly challenging setups. The different structures
are illustrated in Table \ref{tab:data-sets} by examples where all
forms are in the singular. Distinct sentences were randomly generated
by selecting (different) words from pools of 20 subject/object nouns,
15 verbs, 10 adverbs, 5 prepositions, 10 proper nouns and 10 location
nouns. The items were selected so that their combination would not
lead to semantic anomalies.For each NA-task, we generated singular and
plural versions of each sentence. We refer to each such version as a
\textit{condition}. For NA-tasks that have other nouns occurring between
subject and main verb, we also systematically varied their number,
resulting in four conditions. For example, the NounPP sentence in the
table illustrates the SS (singular-singular) condition. The
corresponding sentences in the other conditions are: ``the boy near
the cars greets the guy'' (SP), ``the boys near the car greet the
guy'' (PS), and ``the boys near the cars greet the guy'' (PP).


\textcolor{red}{Possibly move this to Models or Results section.} For
each NA-task, model performance was evaluated for each of its
conditions separately, by computing its accuracy in predicting the
correct form of the main verb. Specifically, for each sentence from a
condition, the model was presented with all words up to the one
immediately preceding the main verb. If the model assigned higher
likelihood to the correct form of the verb than to its counterpart
with the wrong number, then the trial was marked as a hit.

\yair{perhaps to consider to move these explanations about contrasts to the results section:} Note that 2Adv features the same subject-verb
distance as NamePP, but without gender-carrying words acting as
possible distractors in the middle. Similarly, CoAdv can serve as a
distractor-free control for NounPP.

Task sata-set sizes across conditions ranged from 600 (Simple) to 18k sentences (relatives),
based on the possibilities for variation allowed by the combinatorics
given each structure.\footnote{We uploaded the data-set generation
  script as supplementary material.}

Finally, we also used the naturalistic, corpus-derived agreement test set of \newcite{Linzen:etal:2016}, in the version made available by \newcite{Gulordava:etal:2018}.

\subsection{Number of open nodes}\label{ssec:n_opennodes}

For each length between ???? and ????, we randomly sampled 300 sentences
containing different syntactic structures following the same grammar that we
used to generate the NA-tasks \yair{I don't think that it's the 'same grammar'. perhaps Marco can elaborate on the important points to make here.}. For each position in each sentence, we computed
the number of open nodes in the syntactic tree following the same procedure of
\newcite{Nelson:etal:2017}. Since, as noted by \newcite{Conneau:etal:2018}, the
number of open nodes is correlated with the position of the word in the
sentence, we only added to our dataset points (given by a sentence at a given
position) such that the two would be decorrelated.  For this, we picked
examples that would uniformly cover all possible combinations in a range of
word position (between 7 and 12) and number of open nodes (between 3 and 8).
The final dataset is composed by a list of sentences and the positions
within these sentences that we sampled in the decorrelation procedure. In
total, our dataset contains ???? points from ???? sentences.
