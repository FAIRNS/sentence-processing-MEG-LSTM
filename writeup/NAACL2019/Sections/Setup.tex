\section{Setup}\label{sec:the_data}

\paragraph{LSTM language model}\label{ssec:lstm_lm}
We study the pretrained LSTM made available by
\newcite{Gulordava:etal:2018}. This model is composed of a
650-dimensional embedding layer, two 650-dimensional hidden layers,
and an output with vocabulary size 50,000.
The model was trained with the language
model objective on Wikipedia data, without fine-tuning for number
agreement, and obtained perplexity close to state of the art in the experiments of Gulordava et al.\footnote{For robustness, key findings reported below were also replicated with the same model trained with different initialization seeds and variations with different hyper-parameters.} 


\paragraph{Number-agreement tasks}
\begin{table}[tb]
  \centering
  \begin{footnotesize}
  \begin{tabular}{l@{\hskip1pt}l}
    \B Simple & the \textbf{boy} \textbf{greets} the guy\\
    \B Adv & the \textbf{boy} probably \textbf{greets} the guy\\
    \B 2Adv & the \textbf{boy} most probably \textbf{greets} the guy\\
    \B CoAdv &  the \textbf{boy} openly and deliberately \textbf{greets} the guy\\
    \B NamePP & the \textbf{boy} near Pat \textbf{greets} the guy\\
    \B NounPP & the \textbf{boy} near the car \textbf{greets} the guy\\
    \B NounPPAdv & the \textbf{boy} near the car kindly \textbf{greets} the guy\\
  \end{tabular}
  \end{footnotesize}
  \caption{NA tasks illustrated by representative
    singular sentences.}
  \label{tab:data-sets}
\end{table}

We complement analysis of the naturalistic, corpus-derived
number-agreement test set of \newcite{Linzen:etal:2016}, in the
version made available by \newcite{Gulordava:etal:2018}, with
synthetically generated data-sets. Each synthetic number-agreement
task (NA-task) instantiates a fixed syntactic structure with varied
lexical material, in order to probe subject-verb number agreement in
controlled and increasingly challenging setups.\footnote{We exclude,
  for the time being, agreement across a relative clause, as it comes
  with the further complication of accounting for the extra agreement
  process taking place inside the relative clause.} The different
structures are illustrated in Table \ref{tab:data-sets} by examples
where all forms are in the singular. Distinct sentences were randomly
generated by selecting (different) words from pools of 20
subject/object nouns, 15 verbs, 10 adverbs, 5 prepositions, 10 proper
nouns and 10 location nouns. The items were selected so that their
combination would not lead to semantic anomalies. For each NA-task, we
generated singular and plural versions of each sentence. We refer to
each such version as a \textit{condition}. For NA-tasks that have
other nouns occurring between subject and main verb, we also
systematically vary their number, resulting in two \textit{congruent}
and two \textit{incongruent} conditions. For example, the NounPP
sentence in the table illustrates the congruent SS (singular-singular)
condition and the corresponding sentence in the incongruent PS
(plural-singular) condition is: ``the \emph{boys} near the \emph{car}
\emph{greet} the guy''. For all NA-tasks, each condition consisted of
600 sentences

\paragraph{Syntactic depth data-set} We probed the model implicit
syntax parsing abilities by testing whether its representations
predict the syntactic depth of the words they process. Following
\newcite{Nelson:etal:2017}, this was operationalized as predicting the
number of open syntactic nodes at each word, given the canonical
syntactic parse of a sentence.  We generated a data-set of sentences with
unambiguous but varied syntactic structures (for example:
``Ten$_1$ really$_2$ ecstatic$_3$ cousins$_3$ of$_4$ four$_5$ teachers$_6$
are$_2$ quickly$_3$ laughing$_4$", where indexes show the corresponding
number of open nodes).
Since syntactic depth is
naturally correlated with the position of a word in a sentence, we
used a data-point sampling strategy de-correlating these factors. For
each length between 2 and 25 words, we randomly generated 300
sentences. From this set, we randomly picked examples uniformly
covering all possible position-depth combinations within the 7-12
position and 3-8 depth ranges. The final data-set contains 18,605
positions from 23,450 sentences.\footnote{All our data-sets are
  uploaded as supplementary materials and will be openly released upon
  publication.}